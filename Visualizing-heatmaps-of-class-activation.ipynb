{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras import backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Note that we are including the densely-connected classifier on top;\n",
    "# all previous times, we were discarding it.\n",
    "model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](elephant.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# The local path to our target image\n",
    "img_path = 'img/elephant.jpg'\n",
    "\n",
    "# `img` is a PIL image of size 224x224\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# `x` is a float32 Numpy array of shape (224, 224, 3)\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# We add a dimension to transform our array into a \"batch\"\n",
    "# of size (1, 224, 224, 3)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# Finally we preprocess the batch\n",
    "# (this does channel-wise color normalization)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504458', 'African_elephant', 0.9094213), ('n01871265', 'tusker', 0.08618258), ('n02504013', 'Indian_elephant', 0.004354576)]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the \"african elephant\" entry in the prediction vector\n",
    "african_elephant_output = model.output[:, 386]\n",
    "\n",
    "# The is the output feature map of the `block5_conv3` layer,\n",
    "# the last convolutional layer in VGG16\n",
    "last_conv_layer = model.get_layer('block5_conv3')\n",
    "\n",
    "# This is the gradient of the \"african elephant\" class with regard to\n",
    "# the output feature map of `block5_conv3`\n",
    "grads = K.gradients(african_elephant_output, last_conv_layer.output)[0]\n",
    "\n",
    "# This is a vector of shape (512,), where each entry\n",
    "# is the mean intensity of the gradient over a specific feature map channel\n",
    "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "# This function allows us to access the values of the quantities we just defined:\n",
    "# `pooled_grads` and the output feature map of `block5_conv3`,\n",
    "# given a sample image\n",
    "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "\n",
    "# These are the values of these two quantities, as Numpy arrays,\n",
    "# given our sample image of two elephants\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "\n",
    "# We multiply each channel in the feature map array\n",
    "# by \"how important this channel is\" with regard to the elephant class\n",
    "for i in range(512):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "# The channel-wise mean of the resulting feature map\n",
    "# is our heatmap of class activation\n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f94e638cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# We use cv2 to load the original image\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# We resize the heatmap to have the same size as the original image\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "# We convert the heatmap to RGB\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "# We apply the heatmap to the original image\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "# 0.4 here is a heatmap intensity factor\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "\n",
    "# Save the image to disk\n",
    "cv2.imwrite('elephant_cam.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](elephant_cam.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
